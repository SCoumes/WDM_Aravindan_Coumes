\documentclass[10pt]{beamer}
\usepackage[latin1]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{xcolor}
\usepackage{color}
%\usepackage{colortbl,hhline}
\usepackage{colortbl}
\usepackage{float}
\usepackage{tabularx}
\usepackage{multirow}
%\usepackage{graphicx}
%\usepackage{subfig}
\usepackage{stmaryrd}

% Drawing trees
  \usepackage{verbatim}
  \usepackage{tikz}
  \usetikzlibrary{positioning}
  \usetikzlibrary{arrows}
%\usepackage{graphicx}
%\usepackage{times}
%\usepackage{graphics}
%\usepackage{amssymb}
%\usepackage{stmaryrd}
%\usepackage{subfig}
%\usepackage{soul}
%\usepackage{ulem}
\usetheme{Berlin}
%\usepackage{array}
\addtobeamertemplate{footline}{\insertframenumber/\inserttotalframenumber}

\newtheorem{defi}{Definition}
\setbeamertemplate{navigation symbols}{}
\newenvironment{boxedSC}
  {\begin{center}
  \begin{tabular}{|p{0.9\textwidth}|}
  \hline
  }
  {
  \\\hline
  \end{tabular}
  \end{center}
  }
\newcommand\ExAside[1]{\begin{boxedSC} {\center #1} \end{boxedSC}}

\newcommand\SC[1]{{\color{violet}{\it \bf Simon :} #1}}

\title{Web data management : bad academic practices in business study}
\author{Priyanka Aravindan and Simon Coumes}
\date{}
  
\begin{document}

\begin{frame}
%\vspace{-1cm}
\titlepage
\end{frame}

\begin{frame}{Overview}
  
  \end{frame}

\begin{frame}{Data sources}
    \begin{columns}
    \begin{column}{0.5\textwidth}
   	Articles and citations : 
	\begin{itemize}
	  \item Arxiv
	  \item Google scholar
	  \item Semantic scholar
	\end{itemize}
    \end{column}
    \begin{column}{0.5\textwidth}  %%<--- here
      	Affiliations : 
        \begin{itemize}
       	  \item DBLP
	  \item Google scholar
	\end{itemize}
        \end{column}
    \end{columns}

    \vspace{1cm}

    Due to issues (mostly linked with speed), we were unable to get researchers affiliations.

    \vspace{0.75cm}

    The \textbf{Semantic scholar} database gave us articles and citation.
  \end{frame}


\begin{frame}{Measures}
  We want to look at :
  \begin{itemize}
    \item Citation rings
    \item Parasites adding their name to too many papers
    \item Excessive self citation
  \end{itemize}
  \end{frame}

\begin{frame}{The semantic scholar dataset}
     \begin{columns}
    \begin{column}{0.5\textwidth}
   	Size and limitations : 
	\begin{itemize}
	  \item about 150 GB of metadata
	  \item 10 GB left after filtering only business articles
	  \item fast queries $\rightarrow$ we can download the whole dataset
	\end{itemize}
    \end{column}
    \begin{column}{0.5\textwidth}  %%<--- here
      	Structure
        \begin{itemize}
       	  \item List of metadata per article
	  \item All outbound and inbound citations
	  \item Field
	  \item Author ID
	\end{itemize}
        \end{column}
    \end{columns}
  \end{frame}

\begin{frame}{Filter the data}
  A first step was to filter the data and restrain ourselves to articles in the field of business. Total new size : 10 GB. \\

  It is no longer true that all citations point to an article in the database.
  \end{frame}

\begin{frame}{Preprocessing}
  We compute a few useful lookup tables in advance.
  
  \vspace{0.7cm}

  Notably, precompute the matrix of citations from $A$ to $B$ for every pair $(A,B)$ of researchers.
  \end{frame}

\begin{frame}{Citation rings}
  We define a citation ring as a set of 3 authors such that, for each of these authors, most of their citations comme from the others. \\

  Consider four time periods : 
  \begin{enumerate}
    \item before 1990
    \item 1990 - 2000
    \item 2000 - 2010
    \item after 2010
  \end{enumerate}
  \end{frame}

\begin{frame}{Citation rings : algorithm}
  \begin{itemize}
      \item For each author $A$ consider all pairs of other authors that together form more than half the citations received by $A$.
      \item Check if they form a citation ring.
    \end{itemize}
  \end{frame}

\begin{frame}{citation rings : results}

     \begin{center}
     \begin{tabular}{||c c||} 
      \hline
      Time period & number of rings \\
      \hline\hline
      before 1990 & 13 \\ 
      \hline
      1990 - 2000 & 48 \\
      \hline
      2000 - 2010 & 123 \\
      \hline
      after 2010 & 286 \\
      \hline
     \end{tabular}
     \end{center}

     No point in jumping to conclusions. We didn't investigate this.

  \end{frame}

\begin{frame}{Self citation}
  We look at the ration of self citation over total received citations per author. This is easy thanks to the previous preprocessing. 

    \vspace{0.5cm}

     \begin{center}
     \begin{tabular}{||c c c c||} 
      \hline
      time period & more than half & mean self citation score & median\\
      \hline\hline
      before 1990 & 1.6\% & 3.7\% & 0 \\ 
      \hline
      1990 - 2000 & 0.9\% & 3\% & 0 \\
      \hline
      2000 - 2010 & 0.5\% & 2.2\% & 0 \\
      \hline
      after 2010 & 0.2\% & 1.2\% & 0 \\
      \hline
     \end{tabular}
     \end{center}
  \end{frame}

\begin{frame}{Parasites}
  Hello
  \end{frame}

\begin{frame}{Conclusion}
  \begin{itemize}
    \item Data issues : no institution affiliations
    \item very heterogenous dataset
    \item Some suspect results
  \end{itemize}
  \end{frame}

%\begin{frame}{In a few words}
%    \begin{columns}
%    \begin{column}{0.5\textwidth}
%        \begin{itemize}
%            \item Title : Fast Genetic Algorithms
%            \item Date : 2017
%            \end{itemize}
%        \end{column}
%    \begin{column}{0.5\textwidth}  %%<--- here
%        \begin{itemize}
%            \item Authors : Benjamin Doerr, Huu Phuoc Le, Regis Makhmara, Ta Duy Nguyen
%            \item Cited : 121
%            \end{itemize}
%        \end{column}
%    \end{columns}
%    
%    \vspace{0.5cm}
%    
%    Improves on the (1+1) EA, seen as a case study. Introduces \textbf{Fast Genetic Algorithm}. \\
%    $\rightarrow$ superexponential time gain (for the specific kind of goal functions at hand)
%    
%    \end{frame}
%
%\begin{frame}{Jump functions}
%
%    Maximizing Jump functions puts emphasis on the need to change multiple bits to escape local optimums. \\
%
%    \begin{equation}
%    JUMP_{m,n}(x) = \begin{cases}
%    m+\sum_{i=1}^{n} x_{i}  \text{ if }
%        \begin{cases}
%            \text{ either } \sum_{i=1}^{n} x_{i} \leq n-m  \\
%            \text{ or } \sum_{i=1}^{n} x_{i}= n
%        \end{cases}
%    \\
%    n-\sum_{i=1}^{n} x_{i} \text{ otherwise }
%    \end{cases}
%    \end{equation}
%    \end{frame}
%
%\begin{frame}{Jump functions}
%    \begin{figure}
%        \centering
%        \includegraphics[scale = 0.2]{images/kitty.jpeg}
%        \caption{The function $JUMP_{n,m}$ for n = 50 and m = 10}
%    \end{figure}    
%    \end{frame}
%
%\begin{frame}{The standard mutation rate}
%    (1+1) EA with $\frac{1}{n}$ mutation rate $\rightarrow$ $O(n^{m} + n\log n)$ worst case time complexity \\
%    
%    \vspace{1.5cm}
%    
%    The goal is to improve on this by only changing the mutation rate to $\frac{m}{n}$. 
%    
%    
%    \end{frame}
%    
%    \begin{frame}{First results}
%    Mutation rate $\frac{m}{n}$ :
%    
%    \vspace{0.3cm}
%    $\frac{1}{2}\frac{n^m}{m^m}(\frac{n}{n-m})^{n-m}<T_{\frac{m}{n}}<3\frac{n^m}{m^m}(\frac{n}{n-m})^{n-m}$
%    
%    \vspace{0.7cm}
%    For a deviation of $\frac{m}{n}\epsilon$ the deviation factor is at least $\frac{1}{6}exp(\frac{m\epsilon^2}{3})$).
%    \end{frame}
%    
%    
%\begin{frame}{Fmut}
%    The new algorithms are called FEA$_{\beta}$.
%    Randomly choose the mutation rate $X$ to be used at each iteration step. \\
%    
%    \vspace{0.3cm}
%    
%    The article chose a discrete power-law distribution with parameter $\beta$.  \\
%
%    \begin{center}
%    For $j \in [1,\frac{n}{2}]$, 
%    $\mathbb{P}(X = j) = 1 / (j^\beta \sum_{i=1}^{n / 2}i^{-\beta}) $
%    \end{center}
%    
%    \end{frame}
%
%\begin{frame}{Fmut}
%    \begin{figure}
%        \centering
%	\includegraphics[scale = 0.5]{images/kitty.jpeg}
%        \label{fig:my_label}
%    \end{figure}
%    \end{frame}
%    
%\begin{frame}{Conclusion}
%    \begin{itemize}
%        \item Best theoretical rate for jump functions : $\frac{m}{n}$
%        \item This depends on knowing $m$ $\rightarrow$ introduce Fast Genetic Algorithm
%        \item Almost as good for jump functions (loss polynomial in $m$)
%        \item Concretely better than (1+1) EA on vertex cover
%        \item Just an idea introduction on a simple basis $\rightarrow$ more to do on the topic
%        \end{itemize}
%    \end{frame}
%
\end{document}
